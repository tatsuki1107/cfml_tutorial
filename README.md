# Counter Factual Machine Learning Tutorial

# 1. Bandit Algorithm

## On Policy

## Contextual Bandit
### code
<a href="https://github.com/tatsuki1107/cfml_tutorial/blob/master/on_policy/contextual_bandit/contextual_bandit.py">`contextual_bandit.py`</a>

### notebook
- <a href="https://github.com/tatsuki1107/cfml_tutorial/blob/master/on_policy/contextual_bandit/continous_reward.ipynb">`continuous_reward.ipynb`</a>
- <a href="https://github.com/tatsuki1107/cfml_tutorial/blob/master/on_policy/contextual_bandit/binary_reward.ipynb">`binary_reward.ipynb`</a>

### Derivation of policy
- LinUCB:　<a href="https://qiita.com/tatsuki1107/items/02d51371f8db9eccfb30">`LinUCB方策のUCBスコア導出`</a>  
- LinTS: 　<a href="https://qiita.com/tatsuki1107/items/f720a01c4c851345ee32">`LinTS方策における事後分布(ガウス分布)の導出`</a>
- LogisticTS: <a href="https://qiita.com/tatsuki1107/items/b6bfc67be869ea6919e8">`LogisticTS方策におけるラプラス近似した事後分布(ガウス分布)の導出`</a>  

## Off Policy
